{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54bc0ee8",
   "metadata": {},
   "source": [
    "# <center>Data Mining Project Code</center>\n",
    "\n",
    "** **\n",
    "## <center>*Spending Data Segmentation*</center>\n",
    "\n",
    "** **\n",
    "\n",
    "In this notebook, we will implement different clustering methods in order to analyse and group customers by spending-related features.\n",
    "\n",
    "** **\n",
    "The members of the `team` are:\n",
    "- Ana Farinha  - 20211514\n",
    "- António Oliveira - 20211595\n",
    "- Mariana Neto - 20211527\n",
    "- Salvador Domingues - 20240597\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349f819",
   "metadata": {},
   "source": [
    "# ToC\n",
    "\n",
    "<a class=\"anchor\" id=\"top\"></a>\n",
    "\n",
    "\n",
    "1. [Importing Libraries & Data](#1.-Importing-Libraries-&-Data) <br><br>\n",
    "\n",
    "2. [Clustering](#2.-Clustering) <br>\n",
    "\n",
    "    2.1 [Hierarchical Clustering](#2.1-Hierarchical-Clustering) <br><br>\n",
    "    2.2 [K-Means](#2.2-K-Means) <br><br>\n",
    "    2.3 [Self-Organizing Maps (SOM)](#2.3-Self-Organizing-Maps-(SOM)) <br><br>\n",
    "    2.4 [Density-based Clustering](#2.4-Density-based-Clustering) <br><br>\n",
    "    \n",
    "    &emsp; 2.4.1 [Meanshift](#2.4.1-Meanshift)<br><br>\n",
    "    &emsp; 2.4.2 [DBScan](#2.4.2-Density-Based-Spatial-Clustering-of-Applications-with-Noise-(DBSCAN))<br><br>\n",
    "    &emsp; 2.4.3 [HDBScan](#2.4.3-HDBScan)<br><br>\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c1e7a",
   "metadata": {},
   "source": [
    "# 1. Importing Libraries & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "088abf62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:33.911994Z",
     "start_time": "2025-01-03T11:54:31.800698Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display \n",
    "\n",
    "# Scalers\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, \\\n",
    "                                  MinMaxScaler\n",
    "\n",
    "# Clustering algorithms\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import MeanShift, DBSCAN, estimate_bandwidth\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from minisom import MiniSom\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Segmentation\n",
    "import segmentation as s\n",
    "\n",
    "# Visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "import functions as f\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Suppress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path = './plots/spending_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1057c9c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:34.279536Z",
     "start_time": "2025-01-03T11:54:33.914562Z"
    }
   },
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'payment_method', 'promo_DELIVERY', 'promo_DISCOUNT', 'promo_FREEBIE',\n",
    "    'pay_CARD', 'pay_CASH', 'payment_method_enc', 'last_promo_enc'\n",
    "]\n",
    "\n",
    "data = pd.read_csv('data/preprocessed_data.csv', \n",
    "                   index_col = \"customer_id\")\n",
    "spending_data = data[s.spending_orders]\n",
    "spending_data = spending_data.drop(columns=categorical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0646079e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:34.368740Z",
     "start_time": "2025-01-03T11:54:34.281352Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spending_data.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151b0a22",
   "metadata": {},
   "source": [
    "# 2. Clustering\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c6be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import play_song as s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef60098",
   "metadata": {},
   "source": [
    "**Scale Data Before Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77e0c14d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:34.465692Z",
     "start_time": "2025-01-03T11:54:34.454914Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_data = MinMaxScaler().fit_transform(spending_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8565c40",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:34.469719Z",
     "start_time": "2025-01-03T11:54:34.467155Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_data = pd.DataFrame(scaled_data, \n",
    "                           columns=spending_data.columns, \n",
    "                           index=spending_data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f05d9",
   "metadata": {},
   "source": [
    "## 2.1 Hierarchical Clustering\n",
    "\n",
    "To develop a clustering solution using hierarchical clustering, the following steps were carried out:\n",
    "\n",
    "**1. Creating Dendrograms for All Combinations**\n",
    "- Dendrograms were generated for all combinations of linkage methods (e.g., single, complete, average, ward) and distance metrics (e.g., Euclidean, Manhattan).\n",
    "- This step provided a visual representation of the clustering hierarchy to understand how clusters merge at different thresholds.\n",
    "- The dendrograms were analysed to identify configurations that produced distinct and meaningful clusters.\n",
    "\n",
    "**2. Selecting the Best Combinations**\n",
    "- Based on the dendrograms, the most promising combinations of linkage methods and distance metrics were shortlisted.\n",
    "- The selection was based on:\n",
    "  - Clear separation of clusters (visible gaps in the dendrograms).\n",
    "  - Avoidance of configurations that produced excessive chaining effects or imbalanced clusters.\n",
    "- This step narrowed the scope to the most viable configurations.\n",
    "\n",
    "**3. Evaluating the Shortlisted Combinations**\n",
    "- The shortlisted configurations were quantitatively evaluated using the following metrics:\n",
    "  - **R² Score**: Measures how well the clustering structure explains the variance in the data. Higher values indicate a better-defined cluster structure.\n",
    "  - **Silhouette Score**: Evaluates the compactness and separation of clusters. Scores range from -1 (poor clustering) to 1 (ideal clustering), providing insights into cluster quality.\n",
    "  - **Calinski-Harabasz Score**: Assesses the ratio of the sum of cluster dispersion to inter-cluster distances. Higher values indicate well-separated and compact clusters.\n",
    "- By leveraging these metrics, the combination of linkage methods and distance metrics producing the highest-quality clusters was identified and selected.\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd90ba8c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:35.139855Z",
     "start_time": "2025-01-03T11:54:35.137298Z"
    }
   },
   "outputs": [],
   "source": [
    "linkages = [\"complete\", \"average\", \"single\", \"ward\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b9066c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:57:41.803113Z",
     "start_time": "2025-01-03T11:54:35.442803Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f.plot_hierarchical_dendrograms(scaled_data, \n",
    "                                path=path+'euclidean', \n",
    "                                linkages=linkages, \n",
    "                                metrics=['euclidean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7450b444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T12:05:44.479793Z",
     "start_time": "2025-01-03T11:57:41.806118Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f.plot_hierarchical_dendrograms(scaled_data, \n",
    "                                path=path+'others', \n",
    "                                linkages=linkages[:3], \n",
    "                                metrics=['l1', 'l2', 'manhattan',\n",
    "                                         'cosine'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7009465",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T12:23:29.586333Z",
     "start_time": "2025-01-03T12:05:44.482664Z"
    }
   },
   "outputs": [],
   "source": [
    "hr_results = []\n",
    "\n",
    "# Define clustering settings\n",
    "cluster_settings = [\n",
    "    {\"model_type\": \"hierarchical\", \"n_clusters\": k, \"linkage\": 'ward', \"metric\": 'euclidean'}\n",
    "    for k in range(2, 10)\n",
    "] + [\n",
    "    {\"model_type\": \"hierarchical\", \"n_clusters\": k, \"linkage\": 'complete', \"metric\": 'l2'}\n",
    "    for k in range(2, 6)\n",
    "] + [\n",
    "    {\"model_type\": \"hierarchical\", \"n_clusters\": k, \"linkage\": 'complete', \"metric\": 'l1'}\n",
    "    for k in range(2, 7)\n",
    "] + [\n",
    "    {\"model_type\": \"hierarchical\", \"n_clusters\": k, \"linkage\": 'complete', \"metric\": 'manhattan'}\n",
    "    for k in range(2, 5)\n",
    "] \n",
    "\n",
    "# Loop over settings and evaluate models\n",
    "for settings in cluster_settings:\n",
    "    result = f.create_and_evaluate_model(df=scaled_data, feats=scaled_data.columns.tolist(), **settings)\n",
    "    hr_results.append(result)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "hr_results_df = pd.DataFrame(hr_results)\n",
    "hr_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f29e112",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T12:24:24.837686Z",
     "start_time": "2025-01-03T12:24:12.600965Z"
    }
   },
   "outputs": [],
   "source": [
    "import play_song as s\n",
    "s.play_('audio.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e790a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T12:26:46.030166Z",
     "start_time": "2025-01-03T12:26:45.227955Z"
    }
   },
   "outputs": [],
   "source": [
    "f.plot_evaluation_scores(hr_results_df, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3463c81d",
   "metadata": {},
   "source": [
    "**Final Model for Hierarchical Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a5896b85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:19:07.712734Z",
     "start_time": "2025-01-03T14:18:16.980100Z"
    }
   },
   "outputs": [],
   "source": [
    "linkage = 'complete'\n",
    "distance = 'manhattan'\n",
    "n_clusters = 2\n",
    "\n",
    "hclust = AgglomerativeClustering(linkage=linkage, \n",
    "                                 metric=distance, \n",
    "                                 n_clusters=n_clusters)\n",
    "\n",
    "hc_labels = hclust.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e970d02c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:19:08.508413Z",
     "start_time": "2025-01-03T14:19:07.720586Z"
    }
   },
   "outputs": [],
   "source": [
    "f.plot_cluster_profiling(spending_data, hc_labels, \"Hierarchical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3791c9b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:20:02.715937Z",
     "start_time": "2025-01-03T14:19:08.511088Z"
    }
   },
   "outputs": [],
   "source": [
    "umap_object = umap.UMAP(n_neighbors = 5)\n",
    "\n",
    "umap_embedding = umap_object.fit_transform(scaled_data)\n",
    "\n",
    "hc_labels2 = hclust.fit_predict(umap_embedding)\n",
    "\n",
    "f.plot_dim_reduction(umap_embedding, targets = hc_labels2,\n",
    "                   technique = 'Hierarchical Clustering \\\n",
    "                   visualised with UMAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662ea1de",
   "metadata": {},
   "source": [
    "## 2.2 K-Means\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e410a25",
   "metadata": {},
   "source": [
    "To develop an optimal clustering solution using the K-Means algorithm, the following steps were carried out:\n",
    "\n",
    "1. **Using the Elbow Method to Determine a Range for `n_clusters`**\n",
    "- We began by using the **Elbow Method** to determine an appropriate range of values for the `n_clusters` hyperparameter.\n",
    "- By plotting the within-cluster sum of squared distances (inertia) for a range of values of `n_clusters`, we identified the \"elbow point,\" where increasing the number of clusters resulted in diminishing improvements to the inertia.\n",
    "- This step provided a good initial estimate for the potential number of clusters and helped guide further testing.\n",
    "\n",
    "2. **Evaluating Different `n_clusters` Values**\n",
    "- After identifying a range of `n_clusters`, we evaluated different values of `n_clusters` based on various clustering quality metrics:\n",
    "  - **R² Score**\n",
    "  - **Silhouette Score**\n",
    "  - **Calinski-Harabasz Score**\n",
    "- These metrics allowed us to compare the effectiveness of each value for `n_clusters`, providing quantitative insights into cluster quality.\n",
    "\n",
    "3. **Selecting the Optimal `n_clusters`**\n",
    "- After evaluating multiple values for `n_clusters` with the metrics, we selected the value that showed the best balance across all three performance measures.\n",
    "- This value provided the most meaningful and stable clusters, indicating that the K-Means algorithm was able to separate the data in a way that maximized clustering quality.\n",
    "  \n",
    "By focusing primarily on tuning `n_clusters`, we ensured that our clustering solution was optimized and tailored to the specific dataset, ultimately delivering high-quality, interpretable clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff7a955",
   "metadata": {},
   "source": [
    "**Elbow Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4712e9de",
   "metadata": {},
   "source": [
    "The **Elbow Method** is a technique used to determine the optimal number of clusters (`n_clusters`) for K-Means clustering. It involves plotting the within-cluster sum of squared distances (inertia) against different values of `n_clusters`. As the number of clusters increases, the inertia decreases, but at a certain point, the rate of improvement slows down. \n",
    "\n",
    "The \"elbow\" is the point on the plot where the inertia starts to level off, indicating that adding more clusters does not lead to significant improvements in clustering quality. This point suggests the optimal number of clusters to use for the dataset, balancing between overfitting and underfitting the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bb7810a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T13:31:38.370563Z",
     "start_time": "2025-01-03T13:31:24.773309Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dispersion = []\n",
    "for k in range(1, 20):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(scaled_data)\n",
    "    dispersion.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa372764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T13:31:59.310031Z",
     "start_time": "2025-01-03T13:31:59.127546Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(1, 20), dispersion, marker='o', color='#4CAF50')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Dispersion (inertia)')\n",
    "plt.xticks(np.arange(0, 21, step=2))  \n",
    "# plt.vlines(7, 5000, 600000, color='red')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d209e610",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T13:42:26.696194Z",
     "start_time": "2025-01-03T13:41:05.862562Z"
    }
   },
   "outputs": [],
   "source": [
    "results_kmeans = []\n",
    "\n",
    "# Define clustering settings\n",
    "cluster_settings = [\n",
    "    {\"model_type\": \"kmeans\", \"n_clusters\": k, 'random_state': 42} for k in range(2, 8)\n",
    "]\n",
    "\n",
    "# Loop over settings and evaluate models\n",
    "for settings in cluster_settings:\n",
    "    result = f.create_and_evaluate_model(df=scaled_data, feats=scaled_data.columns.tolist(), **settings)\n",
    "    results_kmeans.append(result)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_kmeans_df = pd.DataFrame(results_kmeans)\n",
    "results_kmeans_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f243461",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T13:42:27.644828Z",
     "start_time": "2025-01-03T13:42:26.702821Z"
    }
   },
   "outputs": [],
   "source": [
    "f.plot_evaluation_scores(results_kmeans_df, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd544010",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T13:42:39.240371Z",
     "start_time": "2025-01-03T13:42:27.646964Z"
    }
   },
   "outputs": [],
   "source": [
    "s.play_('audio.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25a8b0a",
   "metadata": {},
   "source": [
    "**Final Solution for K-Means**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7eed9534",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T13:44:36.850083Z",
     "start_time": "2025-01-03T13:44:36.518591Z"
    }
   },
   "outputs": [],
   "source": [
    "number_clusters = 3\n",
    "kmclust = KMeans(n_clusters=number_clusters, \n",
    "                 n_init=15, \n",
    "                 random_state=1)\n",
    "\n",
    "km_labels = kmclust.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670db11e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T13:44:37.457210Z",
     "start_time": "2025-01-03T13:44:36.854133Z"
    }
   },
   "outputs": [],
   "source": [
    "f.plot_cluster_profiling(spending_data, km_labels, \"K-Means\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3521fb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:21:23.971739Z",
     "start_time": "2025-01-03T14:21:11.746498Z"
    }
   },
   "outputs": [],
   "source": [
    "umap_object = umap.UMAP(n_neighbors = 5)\n",
    "\n",
    "umap_embedding = umap_object.fit_transform(scaled_data)\n",
    "\n",
    "kmeans_labels = kmclust.fit_predict(umap_embedding)\n",
    "\n",
    "f.plot_dim_reduction(umap_embedding, targets = kmeans_labels,\n",
    "                   technique = 'K-Means visualised with UMAP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c1b4d0",
   "metadata": {},
   "source": [
    "## 2.3 Self-Organizing Maps (SOM)\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3683a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training a Self-Organized Map with a 15 by 15 grid, using 52 features.\n",
    "som = MiniSom(\n",
    "    15, \n",
    "    15, \n",
    "    52,\n",
    "    sigma=0.5,\n",
    "    learning_rate=1,\n",
    "    neighborhood_function='gaussian',\n",
    "    random_seed=42\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfebb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed of Numpy just to be sure of replicability\n",
    "np.random.seed(42)\n",
    "\n",
    "num_iterations = 1000\n",
    "\n",
    "q_errors = []\n",
    "for i in range(1, num_iterations):\n",
    "    som.train_batch(scaled_data, i)\n",
    "    q_errors.append(som.quantization_error(scaled_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da99ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(q_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the same som again and retraining it \n",
    "som = MiniSom(\n",
    "    15, 15, 52, sigma=0.5, \n",
    "    learning_rate=1, neighborhood_function='gaussian', random_seed=42)\n",
    "som.train(scaled_data, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d4e176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_som_hexagons(som,\n",
    "                      matrix,\n",
    "                      cmap=cm.Blues,\n",
    "                      figsize=(20,20),\n",
    "                      annotate=True,\n",
    "                      title=\"SOM Matrix\",\n",
    "                      cbar_label=\"Color Scale\"\n",
    "                ):\n",
    "\n",
    "    xx, yy = som.get_euclidean_coordinates()\n",
    "\n",
    "    f = plt.figure(figsize=figsize)\n",
    "    ax = f.add_subplot(111)\n",
    "\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_title(title, fontsize=20)\n",
    "\n",
    "    colornorm = mpl_colors.Normalize(vmin=np.min(matrix), \n",
    "                                     vmax=np.max(matrix))\n",
    "\n",
    "    for i in range(xx.shape[0]):\n",
    "        for j in range(xx.shape[1]):\n",
    "            wy = yy[(i, j)] * np.sqrt(3) / 2\n",
    "            hexagon = RegularPolygon((xx[(i, j)], wy), \n",
    "                                 numVertices=6, \n",
    "                                 radius=.95 / np.sqrt(3),\n",
    "                                 facecolor=cmap(colornorm(matrix[i, j])), \n",
    "                                 alpha=1)\n",
    "            ax.add_patch(hexagon)\n",
    "\n",
    "            if annotate:\n",
    "                annot_vals = np.round(matrix[i, j],2)\n",
    "                if annot_vals > 1:\n",
    "                    annot_vals = int(annot_vals)\n",
    "                \n",
    "                ax.text(xx[(i, j)], wy, annot_vals, \n",
    "                        ha='center', va='center', \n",
    "                        fontsize=figsize[1], \n",
    "                        )\n",
    "\n",
    "    ax.margins(.05)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    ## Create a Mappable object\n",
    "    cmap_sm = plt.cm.ScalarMappable(cmap=cmap, norm=colornorm)\n",
    "    cmap_sm.set_array([])\n",
    "    \n",
    "    divider = make_axes_locatable(plt.gca())\n",
    "    ax_cb = divider.new_horizontal(size=\"2%\", pad=0)    \n",
    "    cb1 = colorbar.ColorbarBase(ax_cb, \n",
    "                                orientation='vertical', \n",
    "                                alpha=1,\n",
    "                                mappable=cmap_sm\n",
    "                               )\n",
    "    cb1.ax.get_yaxis().labelpad = 16\n",
    "    cb1.ax.set_ylabel(cbar_label, fontsize=18)\n",
    "    plt.gcf().add_axes(ax_cb)\n",
    "\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101b069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "umatrix = som.distance_map(scaling='mean')\n",
    "\n",
    "fig = plot_som_hexagons(som, umatrix, cmap=cm.RdYlBu_r, title=\"SOM U-Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09cd64",
   "metadata": {},
   "source": [
    "## 2.4 Density-based Clustering\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36734332",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:21:27.487147Z",
     "start_time": "2025-01-03T14:21:27.484188Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "885dbe31",
   "metadata": {},
   "source": [
    "### 2.4.1 Meanshift\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c022d48",
   "metadata": {},
   "source": [
    "**Estimate Bandwidth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b372f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:25:51.252584Z",
     "start_time": "2025-01-03T14:25:19.863335Z"
    }
   },
   "outputs": [],
   "source": [
    "bandwidth = estimate_bandwidth(scaled_data)\n",
    "bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb6f57e",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-03T14:31:10.151Z"
    }
   },
   "outputs": [],
   "source": [
    "ms_results = []\n",
    "\n",
    "# Define clustering settings\n",
    "cluster_settings = [\n",
    "    {\"model_type\": \"meanshift\", 'bandwidth': 0.650878409161391, 'cluster_all': True, 'min_bin_freq': k}\n",
    "    for k in range(1, 5)  \n",
    "] + [\n",
    "    {\"model_type\": \"meanshift\", 'bandwidth': 0.650878409161391, 'cluster_all': False, 'min_bin_freq': k}\n",
    "    for k in range(1, 5)  \n",
    "] \n",
    "# Loop over settings and evaluate models\n",
    "for settings in cluster_settings:\n",
    "    result = f.create_and_evaluate_model(df=scaled_data, feats=scaled_data.columns.tolist(), **settings)\n",
    "    ms_results.append(result)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "ms_results_df = pd.DataFrame(ms_results)\n",
    "ms_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf815f4",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-01-03T14:34:06.664Z"
    }
   },
   "outputs": [],
   "source": [
    "s.play_('audio.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2c111",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True, n_jobs=4)\n",
    "\n",
    "msclust = ms.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915e5fb9",
   "metadata": {},
   "source": [
    "### 2.4.2 Density-Based Spatial Clustering of Applications with Noise (DBSCAN)\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e796ce49",
   "metadata": {},
   "source": [
    "To initialize the DBSCAN clustering algorithm, we first constructed a **K-Distance Graph** to determine an appropriate range for the `eps` hyperparameter. The elbow point in the graph provided a starting point for selecting potential values of `eps`.\n",
    "\n",
    "With the range of `eps` values suggested by the plot, we tested several combinations of hyperparameters, including:  \n",
    "- Different values for `eps`.  \n",
    "- Different algorithm types (`'ball_tree'`, `'kd_tree'`, `'brute'`).  \n",
    "\n",
    "The combinations were then evaluated using the same metrics previously explained:\n",
    "- **R² Score**.  \n",
    "- **Silhouette Score**.  \n",
    "- **Calinski-Harabasz Score**.\n",
    "\n",
    "At the end, we choose our best dbscan solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b980bfe",
   "metadata": {},
   "source": [
    "**Optimimising *Eps* Parameter**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6170c9df",
   "metadata": {},
   "source": [
    "To determine the optimal value for the `eps` parameter in **DBSCAN**, we started by constructing a **K-Distance Graph**. This approach helps visualize the distances to the k-th nearest neighbour for all points in the dataset and guides us in selecting an appropriate `eps` value. The **`eps` (epsilon)** parameter determines the maximum distance between two points to classify them as part of the same cluster in DBSCAN. \n",
    "\n",
    "\n",
    "\n",
    "The **K-Distance Graph** plots the sorted distances to each point’s k-th nearest neighbour. By observing the graph:\n",
    "\n",
    "1. Look for the **elbow point** in the curve. \n",
    "   - This is the region where the distances transition from a gradual increase to a sharp rise. \n",
    "   - The elbow indicates the maximum distance within a cluster before reaching outliers.\n",
    "\n",
    "2. Select an `eps` value slightly larger than the distance at the elbow.\n",
    "   - This ensures all points within dense clusters are captured without including many outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88092f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:24.515452Z",
     "start_time": "2025-01-03T11:54:24.515400Z"
    }
   },
   "outputs": [],
   "source": [
    "# K-distance graph to find the right eps value\n",
    "neigh = NearestNeighbors(n_neighbors=20)\n",
    "neigh.fit(spending_data)\n",
    "distances, _ = neigh.kneighbors(spending_data)\n",
    "distances = np.sort(distances[:, -1])  \n",
    "\n",
    "# Plot the distances\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(distances, label=\"K-distances\", color = \"#568789\")\n",
    "plt.axhline(y=15, color='red', linestyle='--')\n",
    "plt.xlabel(\"Points (sorted by distance)\")\n",
    "plt.ylabel(\"K-distance\")\n",
    "plt.title(\"K-Distance Graph\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0560821f",
   "metadata": {},
   "source": [
    "**Clustering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8813e35e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:24.518790Z",
     "start_time": "2025-01-03T11:54:24.518766Z"
    }
   },
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=15)  \n",
    "spending_data['dbscan'] = dbscan.fit_predict(scaled_data)\n",
    "spending_data['dbscan'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d3c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:24.522738Z",
     "start_time": "2025-01-03T11:54:24.522686Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db_results = []\n",
    "\n",
    "# Define clustering settings\n",
    "cluster_settings = [\n",
    "    {\"model_type\": \"dbscan\", \"eps\": k, \"algorithm\": 'ball_tree'}\n",
    "    for k in range(5, 15)  \n",
    "] + [\n",
    "    {\"model_type\": \"dbscan\", \"eps\": k, \"algorithm\": 'kd_tree'}\n",
    "    for k in range(5, 15)  \n",
    "] + [\n",
    "    {\"model_type\": \"dbscan\", \"eps\": k, \"algorithm\": 'brute'}\n",
    "    for k in range(5, 15)  \n",
    "]\n",
    "\n",
    "# Loop over settings and evaluate models\n",
    "for settings in cluster_settings:\n",
    "    result = create_and_evaluate_model2(df=scaled_data, feats=scaled_data.columns.tolist(), **settings)\n",
    "    db_results.append(result)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "db_results_df = pd.DataFrame(db_results)\n",
    "db_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad540eb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:24.525279Z",
     "start_time": "2025-01-03T11:54:24.525259Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_evaluation_scores(db_results_df, path+'DBScan_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef1e156",
   "metadata": {},
   "source": [
    "### 2.4.3 HDBScan\n",
    "\n",
    "<a href=\"#top\">Top &#129033;</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a6f223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:24.526853Z",
     "start_time": "2025-01-03T11:54:24.526839Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdbscan = HDBSCAN(min_cluster_size = 70, \n",
    "                  cluster_selection_method = 'leaf')\n",
    "spending_data['hdbscan_cluster'] = hdbscan.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d646f368",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:24.529048Z",
     "start_time": "2025-01-03T11:54:24.529027Z"
    }
   },
   "outputs": [],
   "source": [
    "spending_data['hdbscan_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0553cca5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:24.531274Z",
     "start_time": "2025-01-03T11:54:24.531255Z"
    }
   },
   "outputs": [],
   "source": [
    "hdb_results = []\n",
    "\n",
    "# Define clustering settings\n",
    "cluster_settings = [\n",
    "    {\"model_type\": \"hdbscan\", \"min_cluster_size\": k, \"cluster_selection_method\": 'leaf'}\n",
    "    for k in range(5, 75, 10)  \n",
    "] + [\n",
    "    {\"model_type\": \"hdbscan\", \"min_cluster_size\": k, \"cluster_selection_method\": 'eom'}\n",
    "    for k in range(5, 75, 10)  \n",
    "]\n",
    "\n",
    "# Loop over settings and evaluate models\n",
    "for settings in cluster_settings:\n",
    "    result = f.create_and_evaluate_model(df=scaled_data, feats=scaled_data.columns.tolist(), **settings)\n",
    "    hdb_results.append(result)\n",
    "\n",
    "# Convert results to DataFrame\n",
    "hdb_results_df = pd.DataFrame(hdb_results)\n",
    "hdb_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a00d384",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T11:54:24.533822Z",
     "start_time": "2025-01-03T11:54:24.533792Z"
    }
   },
   "outputs": [],
   "source": [
    "f.plot_evaluation_scores(hdb_results_df, path+'HDBScan_scores')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd89356",
   "metadata": {},
   "source": [
    "## 2.5 Gaussian Mixture Model (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8273a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing GMM clustering\n",
    "gmm = GaussianMixture(n_components=4, covariance_type='full', n_init=10, init_params='kmeans', random_state=1)\n",
    "gmm_labels = gmm.fit_predict(scaled_data)\n",
    "labels_proba = gmm.predict_proba(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d8316a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The estimated component weights\n",
    "gmm.weights_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7153e550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The estimated mean vectors of the Components\n",
    "print(gmm.means_.shape)\n",
    "gmm.means_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc2c30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The estimated covariance matrices of the Components\n",
    "gmm.covariances_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec2042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a while to run\n",
    "# \n",
    "# Selecting number of components based on AIC and BIC\n",
    "n_components = np.arange(1, 16)\n",
    "models = [GaussianMixture(n, covariance_type='full', n_init=10, random_state=1).fit(scaled_data)\n",
    "          for n in n_components]\n",
    "\n",
    "bic_values = [m.bic(scaled_data) for m in models]\n",
    "aic_values = [m.aic(scaled_data) for m in models]\n",
    "plt.plot(n_components, bic_values, label='BIC')\n",
    "plt.plot(n_components, aic_values, label='AIC')\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('n_components')\n",
    "plt.xticks(n_components)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f216060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing GMM clustering\n",
    "gmm = GaussianMixture(n_components=3, covariance_type='full', n_init=10, init_params='kmeans', random_state=1)\n",
    "gmm_labels = gmm.fit_predict(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6170ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the labels to spending_data\n",
    "spending_data_concat = pd.concat([scaled_data, pd.Series(gmm_labels, index=scaled_data.index, name=\"gmm_labels\")], axis=1)\n",
    "spending_data_concat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2c74d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the R^2 of the cluster solution\n",
    "sst = f.get_ss(scaled_data)  # get total sum of squares\n",
    "ssw_labels = spending_data_concat.groupby(by='gmm_labels').apply(sst)  # compute ssw for each cluster labels\n",
    "ssb = sst - np.sum(ssw_labels)  # remember: SST = SSW + SSB\n",
    "r2 = ssb / sst\n",
    "print(\"Cluster solution with R^2 of %0.4f\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd59fb",
   "metadata": {},
   "source": [
    "## 2.6 UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d0d794cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:05:03.566273Z",
     "start_time": "2025-01-03T14:04:57.050375Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b9c3514a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:05:03.571796Z",
     "start_time": "2025-01-03T14:05:03.568886Z"
    }
   },
   "outputs": [],
   "source": [
    "umap_object = umap.UMAP(n_neighbors=10, min_dist=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bbe09ec4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:05:42.085297Z",
     "start_time": "2025-01-03T14:05:03.574109Z"
    }
   },
   "outputs": [],
   "source": [
    "num_ordered = spending_data.sort_index()\n",
    "umap_embedding = umap_object.fit_transform(num_ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c85834b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-03T14:05:42.312896Z",
     "start_time": "2025-01-03T14:05:42.089499Z"
    }
   },
   "outputs": [],
   "source": [
    "f.plot_dim_reduction(umap_embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
